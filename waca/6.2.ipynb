{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV #splits up your test set in eqally sized parts, uses one part as test data and the rest as training data. So it optimizes as many classifiers as parts you split your data into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user19\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "\n",
    "df = pd.read_csv('USER-FEATURE-DATA.csv')\n",
    "current_row=0\n",
    "df_sample = pd.DataFrame([],columns=df.columns)\n",
    "for i in np.unique(df['user1']):\n",
    "      new_sample=df[df['user1']==i].sample(n=5)\n",
    "      df_sample=pd.concat([df_sample,new_sample],axis=0)\n",
    "\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "\n",
    "y = df_sample.iloc[:, 0]\n",
    "X = df_sample.iloc[:, 1:]\n",
    "print(y[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n attrb = 101\n",
      "n users = 20\n",
      "SCORE: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jagrit Rai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.0\n",
      "SCORE: 0.0\n",
      "SCORE: 0.0\n",
      "SCORE: 0.0\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "ATTRIBUTES = len(X.columns)-1\n",
    "print('n attrb =', ATTRIBUTES)\n",
    "USERS = y.nunique()\n",
    "print('n users =', USERS)\n",
    "print(USERS)\n",
    "neurons = (ATTRIBUTES + USERS) // 2 \n",
    "clf = MLPClassifier(hidden_layer_sizes=(neurons,), solver='lbfgs', momentum=0.2, learning_rate_init=0.3, random_state=0)\n",
    "clf.n_layers_ = 3\n",
    "clf.max_iter = 1000\n",
    "#got rid of:\n",
    "#hidden_layer_sizes=(1,) (scores all zeroes)\n",
    "#  l\n",
    "#\n",
    "# look into RandomSearchCV\n",
    "param_grid = [\n",
    "        {\n",
    "            'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'solver' : ['lbfgs', 'sgd'],\n",
    "            'hidden_layer_sizes': [\n",
    "              (neurons-10,), (neurons-5,), (neurons,), (neurons+5,), (neurons+10,)\n",
    "             ],\n",
    "             'momentum': [0.1,0.2,0.3],\n",
    "             'learning_rate_init':[0.2,0.3,0.4]\n",
    "        }\n",
    "       ]\n",
    "\n",
    "GRID_SEARCH_TEST = False \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "    if GRID_SEARCH_TEST:\n",
    "        clf = GridSearchCV(MLPClassifier(), param_grid, cv=3, scoring='accuracy')\n",
    "        clf.fit(X_train, y_train)\n",
    "        print('params:', clf.best_params_)\n",
    "    else:\n",
    "      clf.fit(X_train, y_train)\n",
    "      print('SCORE:', clf.score(X_test, y_test))\n",
    "    \"\"\" \n",
    "    EXTRA INFO:\n",
    "    # \n",
    "\n",
    "      print('current loss computed with the loss function: ',clf.loss_)\n",
    "      #print('coefs: ', clf.coefs_)\n",
    "      print('intercepts: ',clf.intercepts_)\n",
    "      print(' number of iterations the solver: ', clf.n_iter_)\n",
    "      print('num of layers: ', clf.n_layers_)\n",
    "      print('Num of o/p: ', clf.n_outputs_) \n",
    "      \n",
    "      \"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b61f3538714a09ae3d3e98b710d5893444287a7cd45d690a9d223e503e88e1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
