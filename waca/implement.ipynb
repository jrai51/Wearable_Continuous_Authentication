{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## IMPORTS ##\n",
    "#############\n",
    "\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "from scipy.fft import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sensor          Time        X         Y         Z\n",
      "11       4  7.210914e+11 -0.11638  0.049002  0.068976\n",
      "8        4  7.210947e+11 -0.11638  0.049002  0.068976\n",
      "4        4  7.210969e+11 -0.11638  0.049002  0.068976\n",
      "13       4  7.211012e+11 -0.11638  0.049002  0.068976\n",
      "9        4  7.211076e+11 -0.11638  0.049002  0.068976\n",
      "    Sensor          Time         X         Y         Z\n",
      "12      10  7.210794e+11 -1.297232 -1.685075  0.404865\n",
      "10      10  7.210914e+11 -1.297232 -1.685075  0.404865\n",
      "2       10  7.210969e+11 -1.297232 -1.685075  0.404865\n",
      "7       10  7.211076e+11 -1.297232 -1.685075  0.404865\n",
      "1       10  7.211231e+11 -1.297232 -1.685075  0.404865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagri\\AppData\\Local\\Temp\\ipykernel_22472\\896904127.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gyro_df.sort_values('Time', inplace=True)\n",
      "C:\\Users\\Jagri\\AppData\\Local\\Temp\\ipykernel_22472\\896904127.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  accel_df.sort_values('Time', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "## PREPROCESSING ##\n",
    "###################\n",
    "## Set the participant we're analyzing\n",
    "\n",
    "PARTICIPANT = \"user1\"\n",
    "DATA_1 = PARTICIPANT+'_1.csv'\n",
    "DATA_2 = PARTICIPANT+'_2.csv'\n",
    "DATA_3 = PARTICIPANT+'_3.csv'\n",
    "\n",
    "#loading data in\n",
    "file_paths = ['user_data\\\\'+PARTICIPANT+'\\\\'+DATA_1, 'user_data\\\\'+PARTICIPANT+'\\\\'+DATA_2, 'user_data\\\\'+PARTICIPANT+'\\\\'+DATA_1 ]\n",
    "f = file_paths[0]\n",
    "gen = pd.read_csv(f, names=['Sensor', 'Time', 'X', 'Y', 'Z'], on_bad_lines='skip') #general data\n",
    "\n",
    "#accel is 10, gyro is 4\n",
    "GYRO_ID = 4\n",
    "ACCEL_ID = 10\n",
    "\n",
    "#Separate data by sensor id \n",
    "gyro_df = gen.loc[gen.Sensor == GYRO_ID]\n",
    "accel_df = gen.loc[gen.Sensor == ACCEL_ID]\n",
    "\n",
    "#sort data by time \n",
    "gyro_df.sort_values('Time', inplace=True)\n",
    "accel_df.sort_values('Time', inplace=True)\n",
    "\n",
    "#data is now separated and ordered by time, ready for M-point filer\n",
    "print(gyro_df.head())\n",
    "print(accel_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x_a       y_a       z_a       x_g       y_g       z_g\n",
      "0    -0.905323 -1.490267  0.412848 -0.116380  0.049002  0.068976\n",
      "1    -0.814532 -1.409798  0.404227 -0.100460  0.045836  0.059477\n",
      "2    -0.723741 -1.329329  0.395607 -0.086671  0.039533  0.053352\n",
      "3    -0.619345 -1.252247  0.388406 -0.069538  0.035982  0.048558\n",
      "4    -0.515988 -1.167866  0.373145 -0.047493  0.034858  0.041812\n",
      "...        ...       ...       ...       ...       ...       ...\n",
      "1495 -0.021500  0.059583 -0.017527 -0.044031  0.225451 -0.099218\n",
      "1496  0.007907  0.018100 -0.135498  0.020388  0.249479 -0.097472\n",
      "1497  0.026544  0.100127 -0.236050  0.065987  0.264570 -0.099158\n",
      "1498  0.030339  0.089896 -0.281496  0.073414  0.273625 -0.098567\n",
      "1499  0.015208  0.005428 -0.261732  0.078090  0.276051 -0.113036\n",
      "\n",
      "[1500 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jagrit Rai\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\Jagrit Rai\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "c:\\Users\\Jagrit Rai\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1797: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, v, pi)\n"
     ]
    }
   ],
   "source": [
    " ##################################\n",
    "# APPLYING MOVING AVERAGE FILTER #\n",
    "##################################\n",
    "\n",
    "#Applying Moving Average Filter \n",
    "\n",
    "\n",
    "M = 9 #M-point filter\n",
    "\n",
    "#starts averaging at Mth point rather than 0th as opposed to vice versa in original paper \n",
    "gyro_df.loc['MA_Time'] = gyro_df['Time'].rolling(M).mean()\n",
    "gyro_df.loc['MA_X'] = gyro_df['X'].rolling(M).mean()\n",
    "gyro_df.loc['MA_Y'] = gyro_df['Y'].rolling(M).mean()\n",
    "gyro_df.loc['MA_Z'] = gyro_df['Z'].rolling(M).mean()\n",
    "\n",
    "accel_df.loc['MA_Time'] = accel_df['Time'].rolling(M).mean()\n",
    "accel_df.loc['MA_X'] = accel_df['X'].rolling(M).mean()\n",
    "accel_df.loc['MA_Y'] = accel_df['Y'].rolling(M).mean()\n",
    "accel_df.loc['MA_Z'] = accel_df['Z'].rolling(M).mean()\n",
    "\n",
    "#Creating axis vectors \n",
    "\n",
    "N = 1500 #number of samples for a profile feature \n",
    "M_IDX = N + M -1#index of the Nth sample (accounts for NaNs of first M rows)\n",
    "\n",
    "\n",
    "#X axis \n",
    "x_a = accel_df.loc[:, \"MA_X\"]\n",
    "x_a = list(x_a[M-1:M_IDX]) #this is done to avoid a keyerror in the loc function \n",
    "\n",
    "x_g = gyro_df.loc[:, \"MA_X\"]\n",
    "x_g = list(x_g[M-1:M_IDX])  \n",
    "\n",
    "#y axis\n",
    "y_a = accel_df.loc[:, \"MA_Y\"]\n",
    "y_a = list(y_a[M-1:M_IDX])\n",
    "\n",
    "y_g = gyro_df.loc[:, \"MA_Y\"]\n",
    "y_g = list(y_g[M-1:M_IDX]) \n",
    "\n",
    "#z axis\n",
    "z_a = accel_df.loc[:, \"MA_Z\"]\n",
    "z_a = list(z_a[M-1:M_IDX])\n",
    "\n",
    "z_g = gyro_df.loc[:, \"MA_Z\"]\n",
    "z_g = list(z_g[M-1:M_IDX])\n",
    "\n",
    "features = {'x_a': x_a, 'y_a': y_a, 'z_a': z_a, 'x_g': x_g, 'y_g': y_g, 'z_g': z_g}\n",
    "features_df = pd.DataFrame.from_dict(features) #mostly for presentation purposes, will come in handy for feature extraction\n",
    "print(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x_a_AADP  x_g_AADP  y_a_AADP  y_g_AADP  z_a_AADP  z_g_AADP  \\\n",
      "0  0.0+0.0j  0.0+0.0j  0.0+0.0j  0.0+0.0j  0.0+0.0j  0.0+0.0j   \n",
      "\n",
      "      x_a_correlation     x_g_correlation     y_a_correlation  \\\n",
      "0  0.410265+0.000000j -0.138125+0.000000j -0.164253+0.000000j   \n",
      "\n",
      "      y_g_correlation  ...        y_a_skewness        y_g_skewness  \\\n",
      "0 -0.107646+0.000000j  ...  0.121019+0.000000j  3.290726+0.000000j   \n",
      "\n",
      "       z_a_skewness      z_g_skewness        x_a_variance        x_g_variance  \\\n",
      "0 -1.10947+0.00000j -1.10947+0.00000j  0.180408+0.000000j  0.115553+0.000000j   \n",
      "\n",
      "         y_a_variance        y_g_variance        z_a_variance  \\\n",
      "0  0.311966+0.000000j  0.063252+0.000000j  0.231176+0.000000j   \n",
      "\n",
      "         z_g_variance  \n",
      "0  0.231176+0.000000j  \n",
      "\n",
      "[1 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "## FEATURE EXTRACTION and USER PROFILING ##\n",
    "###########################################\n",
    "\n",
    "\n",
    "#Mean, Median, Variance, Average Absolute\n",
    "#Difference of Peaks, Range, Mode, Covariance,\n",
    "#Mewan Absolute Deviation (MAD), Inter-\n",
    "#quartile Range (IQR), correlation between axes\n",
    "#(xy, yz, xz), Skewness, Kurtosis\n",
    "\n",
    "\n",
    "def spectral_energy(X):\n",
    "    ''' X is a list of FFT data '''\n",
    "    sum = 0\n",
    "    for item in X:\n",
    "        sum += item #is it supposed to be the square of each item or the square of the total sum?\n",
    "    return sum**2 / len(X)\n",
    "\n",
    "def shannon_entropy(label):\n",
    "    vc = pd.Series(label).value_counts(normalize=True, sort=False)\n",
    "    base = 2\n",
    "    return -(vc * np.log(vc)/np.log(base)).sum()\n",
    "\n",
    "extracted_features = { 'mean': [], 'median': [], 'variance': [], 'AADP': [], 'range': [], 'mode':[], \n",
    "                'covariance': [], 'mad': [], 'iqr': [], 'correlation': [], 'skewness': [], 'kurtosis': [],\n",
    "                'entropy': [], 's_nrg': []} #features in the domain of frequency\n",
    "\n",
    "for column in features_df:\n",
    "    extracted_features['mean'].append(features_df[column].mean())\n",
    "    extracted_features['median'].append(features_df[column].median())\n",
    "    extracted_features['variance'].append(features_df.var()[column])\n",
    "    extracted_features['range'].append(features_df[column].max() - features_df[column].min())\n",
    "    extracted_features['mode'].append(features_df[column].mode().iat[0])\n",
    "    extracted_features['iqr'].append( features_df[column].quantile(0.75) - features_df[column].quantile(0.25))\n",
    "    extracted_features['skewness'].append(features_df[column].skew())\n",
    "    extracted_features['kurtosis'].append(features_df[column].kurtosis())\n",
    "    extracted_features['mad'].append(features_df[column].mad()) \n",
    "    #calculate the FFT for next calculations\n",
    "    col_fft = fft(features_df[column].to_numpy())\n",
    "    extracted_features['entropy'].append(shannon_entropy(column))  \n",
    "    extracted_features['s_nrg'].append(spectral_energy(col_fft)) #what is up with the +0.00j??? \n",
    "\n",
    "\n",
    "    #need fixing :\n",
    "    extracted_features['AADP'].append(0) ######################FIX\n",
    "    \n",
    "\n",
    "labels = ['x_a', 'y_a', 'z_a', 'x_g', 'y_g', 'z_g']\n",
    "extracted_features['covariance'].append(features_df['x_a'].cov(features_df['y_a']))\n",
    "extracted_features['covariance'].append(features_df['x_a'].cov(features_df['z_a']))\n",
    "extracted_features['covariance'].append(features_df['y_a'].cov(features_df['z_a']))\n",
    "extracted_features['covariance'].append(features_df['x_g'].cov(features_df['y_g']))\n",
    "extracted_features['covariance'].append(features_df['x_g'].cov(features_df['z_g']))\n",
    "extracted_features['covariance'].append(features_df['y_g'].cov(features_df['z_g']))\n",
    "\n",
    "extracted_features['correlation'].append(features_df['x_a'].corr(features_df['y_a']))\n",
    "extracted_features['correlation'].append(features_df['x_a'].corr(features_df['z_a']))\n",
    "extracted_features['correlation'].append(features_df['y_a'].corr(features_df['z_a']))\n",
    "extracted_features['correlation'].append(features_df['x_g'].corr(features_df['y_g']))\n",
    "extracted_features['correlation'].append(features_df['x_g'].corr(features_df['z_g']))\n",
    "extracted_features['correlation'].append(features_df['y_g'].corr(features_df['z_g']))\n",
    "\n",
    "feature_set = pd.DataFrame.from_dict(extracted_features, orient='index', columns=labels)\n",
    "\n",
    "\n",
    "user_id = PARTICIPANT\n",
    "t_start = gyro_df.Time.loc[gyro_df.Time.first_valid_index()]\n",
    "t_end = gyro_df.Time.iloc[-1]\n",
    "f_vec = feature_set.unstack().to_frame().sort_index(level=1).T\n",
    "f_vec.columns = f_vec.columns.map('_'.join)\n",
    "\n",
    "user_profile = [user_id, t_start, t_end, f_vec]\n",
    "print(f_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean Distance\n",
    "#distance between two vectors or data points in a coordinate plane.\n",
    "\n",
    "\n",
    "def minkow_dist(x, y, p=2):\n",
    "    '''takes two vectors stored as lists to return minkowski distance. '''\n",
    "    p = 2  #measurement for minkowski distance, euclidean distance when set to 2 \n",
    "    distance_sum = 0   \n",
    "    for i in range(0, len(x)):\n",
    "        distance_sum += (x[i] - y[i])** p\n",
    "\n",
    "    return distance_sum ** (1/p)\n",
    "\n",
    "#manhattan_dist = scipy.cityblock()\n",
    "\n",
    "\n",
    "#if distance < threshold, genuine. if distance >= threshold, imposter\n",
    "\n",
    "#paper also tests cosine distance, correlation distance, manhattan distance and minkowski with p=5. \n",
    "\n",
    "\n",
    "#performance evaluation is calculated using EER; need to do this. \n",
    "\n",
    "#FAR = false acceptance rate, rate of incorrectly accepted unauthorized users among all the unauthorized attempts\n",
    "#FRR = the rate of incorrectly rejected authorized users among all the legitimate authentication attempts \n",
    "#EER = intersection point of FAR and FRR (lower than EER, better the authentication system)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e65e4cc6daf4a8006c5864b45d61f4b85c8e312d3f00cf6ba69baef38219746"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
